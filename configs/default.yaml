# tube2lora default configuration
# This file is the single source of truth for pipeline behavior.

input:
  # One of: channel, playlist, video, url_file
  source_type: channel
  source: "https://www.youtube.com/@example"

download:
  # Shorts and live streams are excluded by default for transcript quality.
  include_shorts: false
  include_live: false

  # media: audio | video | none
  # Audio is default because this is primarily a text-training pipeline.
  media: audio
  keep_video: false
  yt_dlp_audio_format: "bestaudio/best"
  yt_dlp_video_format: "bestvideo+bestaudio/best"

transcribe:
  # faster_whisper | voxtral | youtube_native
  backend: faster_whisper

  # Prefer creator-provided manual transcripts when available.
  # Auto-generated YouTube transcripts are disabled by default.
  prefer_manual_transcript: true
  allow_auto_generated: false

  # If manual transcript exists but is not in allowlist, video is skipped.
  language_allowlist: ["en"]

  faster_whisper:
    model_size: "large-v3"
    device: auto
    compute_type: auto
    beam_size: 5
    vad_filter: true

  voxtral:
    model_name: "mistralai/Voxtral-Mini-4B-Realtime-2602"
    device: auto
    torch_dtype: auto
    chunk_length_s: 30
    batch_size: 4

# OpenAI-compatible endpoint for LLM tasks only (normalize + generate).
llm:
  base_url: "http://127.0.0.1:8000/v1"
  api_key_env: "OPENAI_API_KEY"
  timeout_seconds: 120
  max_retries: 3

normalize:
  enabled: true
  prompt_template: "prompts/normalize_default.yaml"
  model: "mistralai/Ministral-3-14B-Instruct-2512"
  temperature: 0.1
  max_tokens: 4096

analyze:
  enabled: true
  minhash_num_perm: 128

filter:
  enabled: true
  min_words: 100
  language_allowlist: ["en"]
  dedup_threshold: 0.85
  min_quality_score: 0.2

generate:
  enabled: true
  prompt_template: "prompts/video_essay_example.yaml"
  model: "mistralai/Ministral-3-14B-Instruct-2512"
  temperature: 0.1
  max_tokens: 4096
  buffer_chars: 7000
  fallback_min_chars: 2500
  fallback_max_chars: 3500
  min_tail_chars: 800

train:
  enabled: true
  base_model: "unsloth/Ministral-3-3B-Instruct-2512"

  # 4-bit QLoRA default for broader hardware support.
  load_in_4bit: true
  max_seq_length: 16384
  output_name: "ministral3b_tube2lora_adapter"

  # exp4-style baseline
  lora_r: 64
  lora_alpha: 64
  lora_dropout: 0.05
  use_rslora: true

  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  warmup_steps: 15
  num_train_epochs: 4
  learning_rate: 1.0e-4
  weight_decay: 0.01
  lr_scheduler_type: "cosine"
  logging_steps: 5
  save_steps: 50
  dataset_num_proc: 2
  packing: false
  seed: 3407

  # Eval split is video-level, not chunk-level.
  eval_split_ratio: 0.1

evaluate:
  enabled: true
  num_generation_samples: 3
  max_new_tokens: 200
  temperature: 0.7

pipeline:
  continue_on_error: true
  max_failure_rate: 0.2

paths:
  runs_dir: "../runs"
